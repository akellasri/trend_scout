name: Daily Trend Scrape

on:
  push:
    branches:
      - main              # run when you push to main
  schedule:
    - cron: '30 0 * * *'   # daily at 03:00 UTC â€” change if needed
  workflow_dispatch:     # allow manual runs from the Actions UI

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Upgrade pip and install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers (required if your scraper uses Playwright)
        run: |
          python -m pip install playwright
          playwright install --with-deps

      - name: Download spaCy English model
        run: |
          python -m spacy download en_core_web_sm

      - name: Run website scraper (fast mode for Actions)
        run: |
          mkdir -p output
          FNAME="trends-raw-$(date +%F).json"
          echo "Writing to output/$FNAME"
          python extract_trend_metrics_websites-copy.py --limit 2 --no-clip --use-phash --out output/$FNAME

      - name: Upload JSON to Azure Blob (dated)
        env:
          AZURE_STORAGE_CONNECTION_STRING: ${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}
        run: |
          FNAME="trends-raw-$(date +%F).json"
          python upload_to_blob.py output/$FNAME --container trends-raw
          cp output/$FNAME output/latest.json
          python upload_to_blob.py output/latest.json --container trends-raw --dest-path "latest/trends.json"
